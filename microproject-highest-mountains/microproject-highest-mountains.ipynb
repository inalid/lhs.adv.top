{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject: Highest Mountains in the World</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/highest-mountain/\">https://discovery.cs.illinois.edu/microproject/highest-mountain/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source: Wikipedia's \"List of mountains by elevation\"\n",
    "\n",
    "Wikipedia is an absolutely amazing source of information about almost every topic you can imagine!  In this microproject, you will explore how to easily use data in Wikipedia tables as datasets.\n",
    "\n",
    "The Wikipedia article \"[List of mountains by elevation](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation) contains information on hundreds of mountains -- including Mount Everest (tallest in the world), Denali (tallest in the United States), and many more!\n",
    "- Click the link above [(or right here)]((https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)) to view how the Wikipedia page looks in your web browser!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pandas `read_html` function\n",
    "\n",
    "The `pd.read_html(...)` function in the pandas library is designed to read data from tables found in webpages.\n",
    "- `read_html` is very similar to the more commonly used `read_csv`\n",
    "- Instead of returning a DataFrame like `read_csv`, the `read_html` returns a **list of DataFrames** -- one DataFrame for each table!\n",
    "- Just like `read_csv`, you only need to provide the URL of the data!\n",
    "\n",
    "Import `pandas` and create a new variable called `pages` the reads in all of tables on the Wikipedia page  \"[List of mountains by elevation](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'lxml'.  Use pip or conda to install lxml.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[1;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:992\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lxml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/lhs.adv.top/microproject-highest-mountains/microproject-highest-mountains.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-computing-machine-56wxq4577w5cvvj7/workspaces/lhs.adv.top/microproject-highest-mountains/microproject-highest-mountains.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bfictional-computing-machine-56wxq4577w5cvvj7/workspaces/lhs.adv.top/microproject-highest-mountains/microproject-highest-mountains.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m pages \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://en.wikipedia.org/wiki/List_of_mountains_by_elevation\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-computing-machine-56wxq4577w5cvvj7/workspaces/lhs.adv.top/microproject-highest-mountains/microproject-highest-mountains.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m pages\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/html.py:1245\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(io, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1230\u001b[0m     [\n\u001b[1;32m   1231\u001b[0m         is_file_like(io),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     ]\n\u001b[1;32m   1236\u001b[0m ):\n\u001b[1;32m   1237\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing literal html to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mread_html\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. To read from a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1242\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1245\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1246\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[1;32m   1247\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[1;32m   1248\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[1;32m   1249\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1250\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m   1251\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m   1252\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1253\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m   1254\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1255\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1256\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m   1257\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m   1258\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m   1259\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[1;32m   1260\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[1;32m   1261\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[1;32m   1262\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m   1263\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1264\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/html.py:976\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m retained \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[39mfor\u001b[39;00m flav \u001b[39min\u001b[39;00m flavor:\n\u001b[0;32m--> 976\u001b[0m     parser \u001b[39m=\u001b[39m _parser_dispatch(flav)\n\u001b[1;32m    977\u001b[0m     p \u001b[39m=\u001b[39m parser(\n\u001b[1;32m    978\u001b[0m         io,\n\u001b[1;32m    979\u001b[0m         compiled_match,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    984\u001b[0m         storage_options,\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    987\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/html.py:923\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    921\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mbs4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    922\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mlxml.etree\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    924\u001b[0m \u001b[39mreturn\u001b[39;00m _valid_parsers[flavor]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'lxml'.  Use pip or conda to install lxml."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pages = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_mountains_by_elevation\")\n",
    "pages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Data Import\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"pages\" in vars())\n",
    "assert(type(pages[0]) == type(pd.DataFrame()))\n",
    "assert(\"Feet\" in pages[0])\n",
    "assert(\"Range\" in pages[1])\n",
    "assert(\"Mountain\" in pages[2])\n",
    "assert(\"Location and Notes\" in pages[3])\n",
    "assert(\"Metres\" in pages[4])\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the individual DataFrames into one large DataFrame\n",
    "\n",
    "Now that you have **ALL** of the tables in the `pages` variable, we want to convert this into one large DataFrame.  However, instead of having just one DataFrame, the webpage has different tables.\n",
    "\n",
    "Let's explore the individual tables.  Using `pages[0]`, you can view the first table of data found on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pages[1]`, you view the second table that was found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Last DataFrame\n",
    "\n",
    "Continue to look at the tables the Wikipedia page contains.  Find out the **last index** of `pages` that contains data amount the mountains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the DataFrames Together\n",
    "\n",
    "Before we can do analysis on the whole dataset, we need to join the individual tables together.  When we join DataFrames end-to-end, where the last row of the previous DataFrame is followed by the first row of the next DataFrame, the operation is called concatenation.\n",
    "\n",
    "Read the DISCOVERY guide to learn the syntax on \"Combining DataFrames by Concatenation\"\n",
    "- [Guide: \"Combining DataFrames by Concatenation\"](https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/) (https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/)\n",
    "\n",
    "Use concatenation to create a single DataFrame `df` that contains data amount every mountain found on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Data Merging\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df\" in vars())\n",
    "assert(len(df) > len(pages[0]))\n",
    "assert(\"Feet\" in df)\n",
    "assert(\"Mountain\" in df)\n",
    "assert(df[\"Range\"].iloc[35] == \"Hindu Kush\")\n",
    "assert(df[\"Location and Notes\"].iloc[141] == \"Pakistan/Afghanistan\")\n",
    "assert(len(df) > 1500 and len(df) < 1650)\n",
    "assert(len(df[ df[\"Location and Notes\"].str.contains(\"Himalayas\")]) == 35)\n",
    "print(f\"{tada} All Tests Passed! {tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountains in the United States\n",
    "\n",
    "Now that we have every mountain in a single DataFrame, we can do some analysis!  In the dataset, the `Location and Notes` column contains a human-written description of the location and other notes.\n",
    "\n",
    "Create a DataFrame called `df_us` that contains all of the mountains in the United States.\n",
    "\n",
    "- You will need to look back at the [Wikipedia page]((https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/)), or explore `df` here in Python, to find out all the different ways mountains in the United States might be labeled.  *(Hint: There's two different ways!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = ...\n",
    "df_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Percentage of Mountains in the Dataset in the United States?\n",
    "\n",
    "What percentage of mountains in the entire dataset is found in the United States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_us = ...\n",
    "pct_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Mountains\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df_us\" in vars())\n",
    "assert(len(df_us) > 300 and len(df_us) < 400)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Mount Saint Elias\")]) == 1)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Denali\")]) == 1)\n",
    "assert(df_us[\"Feet\"].iloc[128] == 12326)\n",
    "assert(df_us[\"Feet\"].iloc[45] + df_us[\"Feet\"].iloc[33] == 28396)\n",
    "\n",
    "assert(\"pct_us\" in vars())\n",
    "assert(pct_us == len(df_us) / len(df))\n",
    "\n",
    "\n",
    "print(f\"{tada} DataFrame Analysis: All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Microproject - All Checkpoint ðŸ”¬\n",
    "\n",
    "The final check is that you pass all the tests, all at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Final Checkpoint\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"pages\" in vars())\n",
    "assert(type(pages[0]) == type(pd.DataFrame()))\n",
    "assert(\"Feet\" in pages[0])\n",
    "assert(\"Range\" in pages[1])\n",
    "assert(\"Mountain\" in pages[2])\n",
    "assert(\"Location and Notes\" in pages[3])\n",
    "assert(\"Metres\" in pages[4])\n",
    "\n",
    "assert(\"df\" in vars())\n",
    "assert(len(df) > len(pages[0]))\n",
    "assert(\"Feet\" in df)\n",
    "assert(\"Mountain\" in df)\n",
    "assert(df[\"Range\"].iloc[35] == \"Hindu Kush\")\n",
    "assert(df[\"Location and Notes\"].iloc[141] == \"Pakistan/Afghanistan\")\n",
    "assert(len(df) > 1500 and len(df) < 1650)\n",
    "assert(len(df[ df[\"Location and Notes\"].str.contains(\"Himalayas\")]) == 35)\n",
    "\n",
    "\n",
    "assert(\"df_us\" in vars())\n",
    "assert(len(df_us) > 300 and len(df_us) < 400)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Mount Saint Elias\")]) == 1)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Denali\")]) == 1)\n",
    "assert(df_us[\"Feet\"].iloc[128] == 12326)\n",
    "assert(df_us[\"Feet\"].iloc[45] + df_us[\"Feet\"].iloc[33] == 28396)\n",
    "\n",
    "assert(\"pct_us\" in vars())\n",
    "assert(pct_us == len(df_us) / len(df))\n",
    "\n",
    "print(f\"{tada}{tada} All Tests Passed! {tada}{tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  âš ï¸ **Make certain to save your work.** âš ï¸ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/highest-mountain/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
